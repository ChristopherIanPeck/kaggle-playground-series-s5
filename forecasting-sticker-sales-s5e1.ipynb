{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":85723,"databundleVersionId":10652996,"sourceType":"competition"}],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Forecasting Sticker Sales - Playgroud Series S5E1**","metadata":{}},{"cell_type":"markdown","source":"## Import Libraries","metadata":{}},{"cell_type":"code","source":"import requests\nimport holidays\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.linear_model import Ridge\nfrom sklearn.metrics import mean_absolute_percentage_error\nfrom xgboost import XGBRegressor\n\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Data Loading and Initial Configuration","metadata":{}},{"cell_type":"code","source":"TRAIN_CSV = '/kaggle/input/playground-series-s5e1/train.csv'\nTEST_CSV = '/kaggle/input/playground-series-s5e1/test.csv'\n\ntrain_df = pd.read_csv(TRAIN_CSV)\ntest_df = pd.read_csv(TEST_CSV)\n\ntrain_df.date = pd.DatetimeIndex(train_df.date)\ntrain_df['test'] = 0\ntest_df.date = pd.DatetimeIndex(test_df.date)\ntest_df['test'] = 1\n\nclass CFG:\n    years_train = train_df.date.dt.year.unique()\n    years_test = test_df.date.dt.year.unique()    \n    years = np.concatenate((train_df.date.dt.year.unique(), test_df.date.dt.year.unique()))\n    \n    validation_year = 2016\n    \n    countries = train_df.country.unique()\n    stores = train_df.store.unique()\n    products = train_df['product'].unique()\n\n    alpha3 = {'Finland': 'FIN', 'Canada': 'CAN', 'Italy': 'IT', 'Kenya': 'KEN', 'Singapore': 'SGP', 'Norway': 'NOR'}\n\n    countries_2l = {'Finland': 'FI', 'Canada': 'CA', 'Italy': 'IT', 'Kenya': 'KE', 'Singapore': 'SG', 'Norway': 'NO'}\n    \n    holiday_response_len = 10","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Combining Dataframes","metadata":{}},{"cell_type":"code","source":"df = pd.concat((train_df, test_df))\ndf.date = pd.DatetimeIndex(df.date)\ndf['year'] = df['date'].dt.year\ndf['weekday'] = df['date'].dt.weekday\ndf['dayofyear'] = df['date'].dt.dayofyear\ndf['daynum'] = (df.date - df.date.iloc[0]).dt.days\ndf['weeknum'] = df['daynum'] // 7\ndf['month'] = df.date.dt.month","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Sinusoidal Features","metadata":{}},{"cell_type":"code","source":"daysinyear = (df.groupby('year').id.count() / len(CFG.countries) / len(CFG.stores) / len(CFG.products)).rename('daysinyear').astype(int).to_frame()\ndf = df.join(daysinyear, on='year', how='left')\ndf['partofyear'] = (df['dayofyear'] - 1) / df['daysinyear']\ndf['partof2year'] = df['partofyear'] + df['year'] % 2\ndf['partof2year'] = df['partofyear'] + df['year'] % 2\n\nCFG.sincoscol = [f'sin t', f'cos t', f'sin t/2', f'cos t/2']\nCFG.sincoscol2 = [f'sin 2t', f'cos 2t', f'sin t', f'cos t', f'sin t/2', f'cos t/2']\ndf['sin 4t'] = np.sin(8 * np.pi * df['partofyear'])\ndf['cos 4t'] = np.cos(8 * np.pi * df['partofyear'])\ndf['sin 3t'] = np.sin(6 * np.pi * df['partofyear'])\ndf['cos 3t'] = np.cos(6 * np.pi * df['partofyear'])\ndf['sin 2t'] = np.sin(4 * np.pi * df['partofyear'])\ndf['cos 2t'] = np.cos(4 * np.pi * df['partofyear'])\ndf['sin t'] = np.sin(2 * np.pi * df['partofyear'])\ndf['cos t'] = np.cos(2 * np.pi * df['partofyear'])\ndf['sin t/2'] = np.sin(np.pi * df['partof2year'])\ndf['cos t/2'] = np.cos(np.pi * df['partof2year'])\ndf.drop(['daysinyear', 'partofyear', 'partof2year'], axis=1, inplace=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## GDP Factor","metadata":{}},{"cell_type":"code","source":"def get_gdp_per_capita(country,year):\n    url=\"https://api.worldbank.org/v2/country/{0}/indicator/NY.GDP.PCAP.CD?date={1}&format=json\".format(CFG.alpha3[country],year)\n    response = requests.get(url).json()\n    return response[1][0]['value']\n\ngdp = np.array([[get_gdp_per_capita(country, year) for year in CFG.years] for country in CFG.countries])\ngdp_df = pd.DataFrame(gdp, index=train_df.country.unique(), columns=CFG.years)\n\ndf['gdp_factor'] = None\nfor year in CFG.years:\n    for country in CFG.countries:\n        df.loc[(df.country == country) & (df.year == year), 'gdp_factor'] = gdp_df.loc[country, year]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Store Factor\nExcluding Canada and Kenya because of missed values","metadata":{}},{"cell_type":"code","source":"df_no_can_ken = df[~df.country.isin(('Canada', 'Kenya'))]\n\nstore_df = df_no_can_ken.groupby(by='store').num_sold.mean().rename('store_factor').to_frame()\ndf = df.drop('store_factor', axis=1, errors='ignore').join(store_df, on='store', how='left')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Product Factor\nExcluding Canada and Kenya because of missed values","metadata":{}},{"cell_type":"code","source":"df_no_can_ken = df[~df.country.isin(('Canada', 'Kenya'))].copy()\n\ntotal = df_no_can_ken.groupby(by='date').num_sold.sum().rename('num_sold_total')\ndf_no_can_ken = df_no_can_ken.join(total, on='date', how='left')\ndf_no_can_ken['num_sold_ratio'] = df_no_can_ken['num_sold'] / df_no_can_ken['num_sold_total']\n\nplt.figure(figsize=(24, 6))\ndf['product_factor'] = None\nfor product in CFG.products:\n    df_no_can_ken_date = df_no_can_ken[(df_no_can_ken['product'] == product) & (df_no_can_ken['test'] == 0)].groupby(by='date')\n    x = df_no_can_ken_date[CFG.sincoscol].mean().to_numpy()\n    y = df_no_can_ken_date.num_sold_ratio.sum().to_numpy()\n\n    reg = Ridge()\n    reg.fit(x, y)\n    p = reg.predict(x)\n    df.loc[(df['product'] == product), 'product_factor'] = reg.predict(df.loc[(df['product'] == product), CFG.sincoscol].to_numpy())\n   \n    plt.plot(y, 'b')\n    plt.plot(p, 'r')\nplt.show();","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Day of the Week","metadata":{}},{"cell_type":"code","source":"df['holiday'] = 0\n\nfor country in CFG.countries:\n    days = [str(day) for day in holidays.CountryHoliday(CFG.countries_2l[country], years=CFG.years)]\n    df.loc[(df.country==country) & (df.date.isin(days)), 'holiday'] = 1\n\nnum_sold_per_week_country_weekday = df.groupby(['weeknum', 'country', 'weekday'])['num_sold'].sum().reset_index().pivot(index=['weeknum', 'country'], columns='weekday')\nratio_sold_per_week_country_weekday = num_sold_per_week_country_weekday.apply(lambda row: row/sum(row), axis=1).reset_index()\n\nratio_weekday = pd.DataFrame(columns=CFG.countries, data=[[0, ]*len(CFG.countries)]*7)\n\nfor n, country in enumerate(CFG.countries):\n    for d in range(7):\n        dt = ratio_sold_per_week_country_weekday.loc[ratio_sold_per_week_country_weekday.country == country, ('num_sold', d)][:-60]\n        ratio_weekday.loc[d, country] = dt.median()\n\nratio_weekday_mean = ratio_weekday.mean(axis=1)\nratio_weekday['mean'] = ratio_weekday_mean\n\ndf['weekday_factor'] = df.weekday.map(ratio_weekday_mean)\n\n# Total ratio - all factors\ndf['ratio'] = df['gdp_factor'] * df['product_factor'] * df['store_factor'] * df['weekday_factor']\n\n# Total sold items - all factors\ndf['total'] = df['num_sold'] / df['ratio']","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## The General Dependence on The Day of Year","metadata":{}},{"cell_type":"code","source":"df_holidays = df.copy()\ndf_holidays['holiday_response'] = 0\nfor country in CFG.countries:\n    for holiday, _ in holidays.CountryHoliday(CFG.countries_2l[country], years=CFG.years).items():\n        df_holidays.loc[(df_holidays.country==country) & df_holidays.date.isin(pd.date_range(holiday, periods=CFG.holiday_response_len)), 'holiday_response'] = 1\n\nfig = plt.figure(figsize=(24,6))\ndata = pd.DataFrame()\nfor n, country in enumerate(CFG.countries):\n    dt = df_holidays[(df_holidays.country==country) & (df_holidays.holiday_response == 0)].groupby(['dayofyear']).total.median()\n    data[country]= dt\n    plt.plot(dt, label=country)\ndata['median'] = data.median(axis=1)\n\n# Linear regression on fourier series\nx = data.index.to_numpy()\ny = data['median'].to_numpy()\nfourier = lambda t: np.array([np.sin(2*np.pi/365*t), np.cos(2*np.pi/365*t)])\n\nyear_ratio = Ridge(alpha=0.01).fit(fourier(x).T, y.T).predict(fourier(np.arange(1, 366)).T)\nyear_ratio = np.append(year_ratio, year_ratio[-1])\n\ndf['dayofyear_factor'] = df.dayofyear.map(dict(zip(np.arange(1, 367), year_ratio)))\n\n# Total ratio - all factors\ndf['ratio'] = df['gdp_factor'] * df['product_factor'] * df['store_factor'] * df['weekday_factor'] * df['dayofyear_factor']\n\n# Total sold items - all factors\ndf['total'] = df['num_sold'] / df['ratio']\n\nplt.plot(year_ratio, 'k', linewidth=4)\nplt.legend();","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## The sincos Dependence on The Day of Year\n\nMoreover, we can see a periodic dependence on the longer time periods. We can take this into account, too, by incorporating more fourier members.","metadata":{}},{"cell_type":"code","source":"fig = plt.figure(figsize=(24,6))\ndata = pd.DataFrame()\nfor n, country in enumerate(CFG.countries):\n    dt = df_holidays[(df_holidays.test == 0) & (df_holidays.country==country) & (df_holidays.holiday_response == 0)].groupby(['date']).total.median()\n    data[country]= dt\n    plt.plot(dt, label=country)\ndata['median'] = data.median(axis=1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"CFG.sincoscol2 = ['sin 4t', 'cos 4t', 'sin 3t', 'cos 3t', 'sin 2t', 'cos 2t', 'sin t', 'cos t', 'sin t/2', 'cos t/2']\n\n# Linear regression on fourier series\ndfsc = df[df.test == 0].groupby('date')[CFG.sincoscol2].mean()#.to_numpy()\ndfsc['median'] = data['median']\n\nx = dfsc[~pd.isna(dfsc['median'])][CFG.sincoscol2].to_numpy()\ny = dfsc[~pd.isna(dfsc['median'])]['median'].to_numpy()\n\nreg = Ridge(alpha=0.01, fit_intercept=True)\nreg.fit(x, y)\n\nfig = plt.figure(figsize=(24,6))\nplt.plot(y, 'k')\nplt.plot(reg.predict(x), 'r')\n\ndf['sincos_factor'] = reg.intercept_ + (df[CFG.sincoscol2] * reg.coef_).sum(axis=1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Country Factor\n\nKenyan sales are different from the other 'countries'. So, it seems a good idea to introduce additional country-related feature.\n\nUsing the `Kaggle` product that has no missing values.","metadata":{}},{"cell_type":"code","source":"# Total ratio - all factors\ndf['ratio'] = df['gdp_factor'] * df['product_factor'] * df['store_factor'] * df['weekday_factor'] * df['sincos_factor']\n\n# Total sold items - all factors\ndf['total'] = df['num_sold'] / df['ratio']\n\nfig = plt.figure(figsize=(24,6))\nfor c in CFG.countries:\n    df_p = df[(df.country == c) & (df['product'] == 'Kaggle')].groupby('date').total.sum().to_numpy()\n    plt.plot(df_p, label=c)\n\nplt.legend();","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"country_factor = df[(df['product'] == 'Kaggle')].groupby('country').total.sum().rename('country_factor')\ncountry_factor = country_factor / country_factor.median()\ndf = df.join(country_factor, on='country', how='left')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Prediction","metadata":{}},{"cell_type":"code","source":"df['ratio'] = df['gdp_factor'] * df['product_factor'] * df['store_factor'] * df['weekday_factor'] * df['sincos_factor'] * df['country_factor']\n\ndf['total'] = df['num_sold'] / df['ratio']\nconst_factor = df['total'].median() * 1.06\n\ndf['prediction'] = const_factor * df['ratio']\nmape_train = mean_absolute_percentage_error(df[(df.test == 0) & (~pd.isna(df.num_sold))].num_sold, df[(df.test == 0) & (~pd.isna(df.num_sold))].prediction)\n\nprint(f'{mape_train=}')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Convert to Integer\nSince we are worlking with units of products it best to round to whole numbers.","metadata":{}},{"cell_type":"code","source":"df['prediction'] = np.round(df['prediction'].astype(float)).astype(int)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##  Ablation Studie\nAblation studies to evaluate the contribution of each factor","metadata":{}},{"cell_type":"code","source":"factors = ['gdp_factor', 'product_factor', 'store_factor', 'weekday_factor', 'sincos_factor', 'country_factor']\n\n\n# Baseline MAPE\nbaseline_mape = mean_absolute_percentage_error(\n    df[(df.test == 0) & (~pd.isna(df.num_sold))].num_sold,\n    df[(df.test == 0) & (~pd.isna(df.num_sold))].prediction\n)\nprint(f\"Baseline MAPE: {baseline_mape:.4f}\")\n\n# Ablation Study\nfor factor in factors:\n    temp_factors = [f for f in factors if f != factor]\n    df['ratio_temp'] = df[temp_factors].prod(axis=1)\n    df['prediction_temp'] = const_factor * df['ratio_temp']\n    mape_temp = mean_absolute_percentage_error(\n        df[(df.test == 0) & (~pd.isna(df.num_sold))].num_sold,\n        df[(df.test == 0) & (~pd.isna(df.num_sold))].prediction_temp\n    )\n    print(f\"MAPE without {factor}: {mape_temp:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Insights\n**sincos_factor** is Critical:  \nThis is the most important factor for the model. Without it, the model fails to capture periodic dependencies and seasonality, leading to extreme errors.\n\n\n**gdp_factor, product_factor, store_factor, and weekday_factor** are Highly Important:  \nEach of these factors substantially impacts model performance and should remain in the feature set.\n\n**country_factor** is Less Critical:  \nWhile it adds value, removing it only slightly increases MAPE, indicating that it is not as essential as the other factors.","metadata":{}},{"cell_type":"markdown","source":"##  Ablation Studie 2\nAblation studies to evaluate the addition of **sincos_factor** and removal of **country_factor**","metadata":{}},{"cell_type":"code","source":"# Add new Fourier terms\ndf['sin 5t'] = np.sin(10 * np.pi * df['partofyear'])\ndf['cos 5t'] = np.cos(10 * np.pi * df['partofyear'])\ndf['sin 6t'] = np.sin(12 * np.pi * df['partofyear'])\ndf['cos 6t'] = np.cos(12 * np.pi * df['partofyear'])\n\n\nCFG.sincoscol2.extend(['sin 5t', 'cos 5t', 'sin 6t', 'cos 6t'])\n\n# Recalculate sincos_factor with additional terms\nx_expanded = dfsc.dropna()[CFG.sincoscol2].to_numpy()\nreg_expanded = Ridge(alpha=0.01, fit_intercept=True)\nreg_expanded.fit(x_expanded, y)\n\n# Add expanded sincos_factor\ndf['sincos_factor_expanded'] = reg_expanded.intercept_ + (df[CFG.sincoscol2] * reg_expanded.coef_).sum(axis=1)\n\n# Update the ratio and prediction\ndf['ratio_expanded'] = df[['gdp_factor', 'product_factor', 'store_factor', 'weekday_factor', 'sincos_factor_expanded']].prod(axis=1)\ndf['prediction_expanded'] = const_factor * df['ratio_expanded']\n\n# Calculate MAPE with expanded Fourier terms and country_factor removed\nmape_expanded = mean_absolute_percentage_error(\n    df[(df.test == 0) & (~pd.isna(df.num_sold))].num_sold,\n    df[(df.test == 0) & (~pd.isna(df.num_sold))].prediction_expanded\n)\nprint(f\"MAPE with expanded Fourier terms: {mape_expanded:.4f}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"factors = ['gdp_factor', 'product_factor', 'store_factor', 'weekday_factor', 'sincos_factor']\n\n# MAPE with expanded Fourier terms and country_factor removed\nmape_expanded = mean_absolute_percentage_error(\n    df[(df.test == 0) & (~pd.isna(df.num_sold))].num_sold,\n    df[(df.test == 0) & (~pd.isna(df.num_sold))].prediction_expanded\n)\nprint(f\"MAPE with expanded Fourier terms: {mape_expanded:.4f}\")\n\n# Ablation Study 2\nfor factor in factors:\n    temp_factors = [f for f in factors if f != factor]\n    df['ratio_temp'] = df[temp_factors].prod(axis=1)\n    df['prediction_temp'] = const_factor * df['ratio_temp']\n    mape_temp = mean_absolute_percentage_error(\n        df[(df.test == 0) & (~pd.isna(df.num_sold))].num_sold,\n        df[(df.test == 0) & (~pd.isna(df.num_sold))].prediction_temp\n    )\n    print(f\"MAPE without {factor}: {mape_temp:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Submission","metadata":{}},{"cell_type":"code","source":"submission = df[(df.test == 1)][['id', 'prediction']].rename(columns={'prediction': 'num_sold'})\nsubmission.to_csv('submission.csv', index=False)\n\n!head submission.csv","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}