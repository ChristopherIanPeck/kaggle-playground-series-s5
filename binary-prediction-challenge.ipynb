{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":91714,"databundleVersionId":11251744,"sourceType":"competition"},{"sourceId":9328134,"sourceType":"datasetVersion","datasetId":5651545}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## **Objective**  \nIn this episode we are given the task of predicting the rainfall for each day of the year. \nSubmissions are evaluated on the **Area Under the Receiver Operating Characteristic Curve** between the predicted probability and the observed target.\n\n**AUC-ROC** is defined as:\n\n$$\n\\textrm{AUC} = \\sum_{i=1}^{n} ( \\textrm{FPR}_i - \\textrm{FPR}_{i-1} ) \\times \\textrm{TPR}_i\n$$\n \n## **Data Overview**  \nThe dataset for this competition is generated from a deep learning model trained on the [Rainfall Prediction using Machine Learning](https://www.kaggle.com/datasets/subho117/rainfall-prediction-using-machine-learning)  \n\n**Key Features:**  \n- **Pressure:** Atmospheric pressure recorded daily.  \n- **Max Temperature (maxtemp):** Highest temperature recorded in a day.  \n- **Temperature:** Average daily temperature.  \n- **Min Temperature (mintemp):** Lowest temperature recorded in a day.  \n- **Dew Point:** Temperature at which condensation occurs.  \n- **Humidity:** Percentage of moisture in the air.  \n- **Cloud Cover:** Extent of cloudiness during the day.  \n- **Sunshine Duration:** Total hours of sunshine received in a day.  \n- **Wind Direction:** Direction from which the wind is blowing.  \n- **Wind Speed:** Speed of the wind measured in a given unit.  \n- **Day:** Recorded day of the year.  ","metadata":{}},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport pandas as pd\nimport numpy as  np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import roc_auc_score, precision_recall_curve, auc\n\n\nsns.set_theme(style=\"whitegrid\", palette=\"muted\")\n\nprint('Libaires imported')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-10T17:35:50.270484Z","iopub.execute_input":"2025-03-10T17:35:50.270749Z","iopub.status.idle":"2025-03-10T17:35:50.281509Z","shell.execute_reply.started":"2025-03-10T17:35:50.270726Z","shell.execute_reply":"2025-03-10T17:35:50.280434Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_data = pd.read_csv('/kaggle/input/playground-series-s5e3/train.csv')\ntest_data = pd.read_csv('/kaggle/input/playground-series-s5e3/test.csv')\noriginal_data = pd.read_csv('/kaggle/input/rainfall-prediction-using-machine-learning/Rainfall.csv')\n\nprint('Data imported')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T17:35:50.283764Z","iopub.execute_input":"2025-03-10T17:35:50.284118Z","iopub.status.idle":"2025-03-10T17:35:50.309978Z","shell.execute_reply.started":"2025-03-10T17:35:50.284093Z","shell.execute_reply":"2025-03-10T17:35:50.308986Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Train Data Preview:\")\ndisplay(train_data.tail())\n\nprint(\"\\nOriginal Data Preview:\")\ndisplay(original_data.tail())\n\nprint(\"\\nTest Data Preview:\")\ndisplay(test_data.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T17:35:50.310993Z","iopub.execute_input":"2025-03-10T17:35:50.311248Z","iopub.status.idle":"2025-03-10T17:35:50.358407Z","shell.execute_reply.started":"2025-03-10T17:35:50.311227Z","shell.execute_reply":"2025-03-10T17:35:50.357326Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Removing whitespace in column names\ntrain_data.columns = train_data.columns.str.strip()\ntest_data.coloumns = test_data.columns.str.strip()\noriginal_data.columns = original_data.columns.str.strip()\n\n# Correct spelling inconsistency in train_data\ntrain_data = train_data.rename(columns={'temparature': 'temperature'})\ntest_data = test_data.rename(columns={'temparature': 'temperature'})\noriginal_data = original_data.rename(columns={'temparature': 'temperature'})\n\n# Converting original dataset 'rainfall' column to binary format\noriginal_data['rainfall'] = (original_data['rainfall'] == 'yes').astype(int)\n\n# Reorder columns in original_data to match train_data\noriginal_data = original_data.reindex(columns=train_data.columns)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T17:35:50.359491Z","iopub.execute_input":"2025-03-10T17:35:50.359791Z","iopub.status.idle":"2025-03-10T17:35:50.368807Z","shell.execute_reply.started":"2025-03-10T17:35:50.359727Z","shell.execute_reply":"2025-03-10T17:35:50.367686Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Train Data Preview:\")\ndisplay(train_data.tail())\n\nprint(\"\\nOriginal Data Preview:\")\ndisplay(original_data.tail())\n\nprint(\"\\nTest Data Preview:\")\ndisplay(test_data.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T17:35:50.370029Z","iopub.execute_input":"2025-03-10T17:35:50.370380Z","iopub.status.idle":"2025-03-10T17:35:50.427121Z","shell.execute_reply.started":"2025-03-10T17:35:50.370347Z","shell.execute_reply":"2025-03-10T17:35:50.426102Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_duplicates = train_data.duplicated().sum()\ntest_duplicates = test_data.duplicated().sum()\noriginal_duplicates = original_data.duplicated().sum()\n\nprint(f'Number of duplicate rows in train_data: {train_duplicates}')\nprint(f'Number of duplicate rows in test_data: {test_duplicates}')\nprint(f'Number of duplicate rows in original_data: {original_duplicates}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T17:35:50.428072Z","iopub.execute_input":"2025-03-10T17:35:50.428318Z","iopub.status.idle":"2025-03-10T17:35:50.442318Z","shell.execute_reply.started":"2025-03-10T17:35:50.428298Z","shell.execute_reply":"2025-03-10T17:35:50.441292Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Missing and unique values\n\nmissing_values_train = pd.DataFrame({'Feature': train_data.columns,\n                                     '[TRAIN] Missing Values': train_data.isnull().sum().values})\n\nmissing_values_test = pd.DataFrame({'Feature': test_data.columns,\n                                     '[TEST] Missing Values': test_data.isnull().sum().values})\n\nmissing_values_original = pd.DataFrame({'Feature': original_data.columns,\n                                       '[ORIGINAL] Missing Values': original_data.isnull().sum().values})\n\nunique_values_train = pd.DataFrame({'Feature': train_data.columns,\n                              '[TRAIN] Unique Values': train_data.nunique().values})\n\nunique_values_test = pd.DataFrame({'Feature': test_data.columns,\n                              '[TEST] Unique Values': test_data.nunique().values})\n\nunique_values_original = pd.DataFrame({'Feature': original_data.columns,\n                              '[ORIGINAL] Unique Values': original_data.nunique().values})\n\n\nfeature_types = pd.DataFrame({'Feature': train_data.columns,\n                              '[TRAIN] DataType': train_data.dtypes})\n\nmerged_df = pd.merge(missing_values_train, missing_values_test, on='Feature', how='left')\nmerged_df = pd.merge(merged_df, missing_values_original, on='Feature', how='left')\nmerged_df = pd.merge(merged_df, unique_values_train, on='Feature', how='left')\nmerged_df = pd.merge(merged_df, unique_values_test, on='Feature', how='left')\nmerged_df = pd.merge(merged_df, unique_values_original, on='Feature', how='left')\nmerged_df = pd.merge(merged_df, feature_types, on='Feature', how='left')\n\nmerged_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T17:35:50.443394Z","iopub.execute_input":"2025-03-10T17:35:50.443657Z","iopub.status.idle":"2025-03-10T17:35:50.483486Z","shell.execute_reply.started":"2025-03-10T17:35:50.443635Z","shell.execute_reply":"2025-03-10T17:35:50.482420Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_data.describe().T","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T17:35:50.484569Z","iopub.execute_input":"2025-03-10T17:35:50.484831Z","iopub.status.idle":"2025-03-10T17:35:50.526987Z","shell.execute_reply.started":"2025-03-10T17:35:50.484809Z","shell.execute_reply":"2025-03-10T17:35:50.525852Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_data.describe().T","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T17:35:50.528047Z","iopub.execute_input":"2025-03-10T17:35:50.528331Z","iopub.status.idle":"2025-03-10T17:35:50.566281Z","shell.execute_reply.started":"2025-03-10T17:35:50.528306Z","shell.execute_reply":"2025-03-10T17:35:50.565146Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"original_data.describe().T","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T17:35:50.567152Z","iopub.execute_input":"2025-03-10T17:35:50.567428Z","iopub.status.idle":"2025-03-10T17:35:50.606603Z","shell.execute_reply.started":"2025-03-10T17:35:50.567407Z","shell.execute_reply":"2025-03-10T17:35:50.605475Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Handling Missing Value**","metadata":{}},{"cell_type":"code","source":"# Missing value in original_data\noriginal_data['winddirection'].fillna(original_data['winddirection'].mean(), inplace=True)\noriginal_data['windspeed'].fillna(original_data['windspeed'].mean(), inplace=True)\n\n# Missing value in test_data\ntest_data['winddirection'].fillna(test_data['winddirection'].mean(), inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T17:36:19.635215Z","iopub.execute_input":"2025-03-10T17:36:19.635531Z","iopub.status.idle":"2025-03-10T17:36:19.642652Z","shell.execute_reply.started":"2025-03-10T17:36:19.635503Z","shell.execute_reply":"2025-03-10T17:36:19.641560Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Data Observations**","metadata":{}},{"cell_type":"markdown","source":"**Temperature:**\n- Max Temp: The mean is approximately 26°C, with a range from about 7°C to 36°C across all datasets.\n- Min Temp: The mean is around 22°C, showing moderate temperature variation.\n- Temperature Variation: Both max and min temperatures indicate a relatively consistent climate with some seasonal variation.\n\n**Humidity Levels:**\n- Average Humidity: Ranges from 80% to 82% across datasets, indicating a humid climate.\n- Consistency: Humidity levels are highly consistent, suggesting a stable atmospheric condition.\n\n**Sunshine & Cloud Cover:**\n- Cloud Cover: Train and test datasets show higher cloudiness (75-76%) compared to the original dataset (71%), indicating more sunny days in the original data.\n- Sunshine Hours: Low average sunshine (3-4 hours), with a maximum of 12.1 hours, suggesting cloudy conditions dominate.\n\n**Wind & Pressure Trends:**\n- Pressure Levels: Consistent mean pressure around 1013 hPa across datasets, indicating stable atmospheric conditions.\n- Wind Speed & Direction: Mean wind speed is about 21-22 km/h, with extreme values up to 59 km/h. Wind direction varies widely (10° to 350°), indicating diverse wind patterns.","metadata":{}},{"cell_type":"markdown","source":"## **EDA**","metadata":{}},{"cell_type":"code","source":"target_variable = 'rainfall'\n\nnumerical_variables = ['winddirection', 'pressure', 'maxtemp', 'temparature', 'mintemp', 'dewpoint', 'humidity', 'cloud', 'sunshine', 'windspeed']\ncategorical_variables = []\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T17:35:50.607653Z","iopub.execute_input":"2025-03-10T17:35:50.608046Z","iopub.status.idle":"2025-03-10T17:35:50.612054Z","shell.execute_reply.started":"2025-03-10T17:35:50.608019Z","shell.execute_reply":"2025-03-10T17:35:50.610950Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Rainfall Distribution**","metadata":{}},{"cell_type":"code","source":"def plot_target_distribution(data, target_variable, title_suffix=\"\"):\n    \n    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n\n    sns.countplot(y=target_variable, data=data, ax=axes[0])\n    axes[0].set_title(f'Distribution of {target_variable} in {title_suffix}')\n    axes[0].set_xlabel('Count')\n    axes[0].set_ylabel(target_variable)\n\n    for p in axes[0].patches:\n        axes[0].annotate(f'{int(p.get_width())}', \n                         (p.get_width(), p.get_y() + p.get_height() / 2), \n                         ha='left', va='center', \n                         fontsize=10)\n\n    axes[0].set_axisbelow(True)\n    axes[0].grid(axis='x', linestyle='--', linewidth=0.7)  \n    sns.despine(left=True, bottom=True)\n\n    rainfall_counts = data[target_variable].value_counts()\n    wedges, texts, autotexts = axes[1].pie(\n        rainfall_counts, \n        labels=rainfall_counts.index, \n        autopct='%1.1f%%', \n        startangle=90\n    )\n    centre_circle = plt.Circle((0, 0), 0.70, fc='white')\n    fig.gca().add_artist(centre_circle)\n    axes[1].set_title(f'Percentage of {target_variable} Distribution in {title_suffix}')\n    axes[1].axis('equal')\n\n    plt.tight_layout()\n    plt.show()\n\n\nplot_target_distribution(train_data, 'rainfall', title_suffix=\"Train Data\")\nplot_target_distribution(original_data, 'rainfall', title_suffix=\"Original Data\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T17:35:50.612944Z","iopub.execute_input":"2025-03-10T17:35:50.613246Z","iopub.status.idle":"2025-03-10T17:35:51.520382Z","shell.execute_reply.started":"2025-03-10T17:35:50.613221Z","shell.execute_reply":"2025-03-10T17:35:51.519309Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Rainfall Distribution Analysis**\n\n**Distribution of Rainfall in Train Data:**\n- **Significant Imbalance:** There is an overrepresentation of instances of rainfall, approximately 75.3% of the data points indicating rainfall while only 24.7% indicate the absence of rain.\n- **Implications for Model Training:** This imbalance could pose a challenge for model training, leading to bias towards the majority class.\n\n**Distribution of Rainfall in Original Data:**\n- **Imbalance Persists:** The original dataset also exhibits imbalance, approximately 68% of the data points indicating rainfall while only 32%% indicate the absence of rain.\n","metadata":{}},{"cell_type":"markdown","source":"## **Numerical Variable Distributions Across Datasets**","metadata":{}},{"cell_type":"code","source":"fig, axes = plt.subplots(len(numerical_variables), 2, figsize=(12, len(numerical_variables) * 4))\n\nfor i, feature in enumerate(numerical_variables):\n    # Histogram\n    sns.histplot(train_data[feature], label='Train Data', bins=20, kde=True, ax=axes[i, 0])\n    sns.histplot(test_data[feature], label='Test Data', bins=20, kde=True, ax=axes[i, 0])\n    sns.histplot(original_data[feature], label='Original Data', bins=20, kde=True, ax=axes[i, 0])\n    axes[i, 0].set_title(f'Histogram of {feature}')\n    axes[i, 0].legend()\n    axes[i, 0].grid(linestyle='--', linewidth=0.7)\n\n    # Horizontal Boxplot\n    sns.boxplot(data=[train_data[feature], test_data[feature], original_data[feature]], \n                orient='h', ax=axes[i, 1])\n    axes[i, 1].set_title(f'Horizontal Boxplot of {feature}')\n    axes[i, 1].set_yticklabels(['Train Data', 'Test Data', 'Original Data'])\n    axes[i, 1].grid(axis='x', linestyle='--', linewidth=0.7)\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T17:35:51.521469Z","iopub.execute_input":"2025-03-10T17:35:51.521762Z","iopub.status.idle":"2025-03-10T17:36:00.100172Z","shell.execute_reply.started":"2025-03-10T17:35:51.521730Z","shell.execute_reply":"2025-03-10T17:36:00.098782Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Numerical Variable Distributions Across Datasets**\n\n**Day:**\n- Train and test data show a relatively uniform distribution. As does the original dataset over a limitted range.  \n- Train and test data likely cover multiple years.\n- The original data represents a smaller limited time period.\n\n**Pressure:**\n- All datasets show a relatively normal distribution centered around a similar mean.\n- Outliers are present in all three data sets.  \n- Atmospheric pressure is relatively stable across all datasets.\n- Their are outliers.\n\n**Maxtemp, Temperature, Mintemp:**\n- These temperature-related features have similar distributions, with a relatively normal shape.  \n- Temperatures are generally consistent across datasets.\n\n**Dewpoint:**\n- The dewpoint distributions are similar across datasets, indicating consistent moisture levels.\n- Slight negative skew is present in all the datasets.  \n- Moisture patterns are relatively stable.\n- Lower dewpoints are less common.\n\n**Humidity:**\n- Humidity levels show consistent distributions, with a slight left skew, indicating a trend towards higher humidity.  \n- The climate is generally humid.  \n\n**Cloud:**\n- Cloud cover shows a bimodal distribution, with peaks at high cloud cover and a secondary peak at lower cloud cover.  \n- The climate experiences both clear and overcast conditions.\n\n**Sunshine:**\n- Sunshine hours are heavily skewed towards lower values.\n- The original dataset has a higher average of sunshine.\n- Cloudy conditions are prevalent.\n\n**Winddirection:**\n- Wind direction shows a relatively uniform distribution, indicating variability in wind patterns.\n- There are a few outliers.  \n- Wind patterns are diverse.\n\n**Windspeed:**  \n- Wind speed is skewed towards lower values, with a long tail indicating occasional high wind speeds.\n- There are a few outliers.  \n- Moderate wind speeds are more common, but strong winds occur.","metadata":{}},{"cell_type":"markdown","source":"## **Correlation Analysis of Numerical Variables**","metadata":{}},{"cell_type":"code","source":"fig, axes = plt.subplots(3, 1, figsize=(10, 18))  \n# Train Data Heatmap\nsns.heatmap(train_data.corr(), cmap='coolwarm', annot=True, fmt='.2f', ax=axes[0])\naxes[0].set_title('Correlation Heatmap - Train Data')\n\n# Original Data Heatmap\nsns.heatmap(original_data.corr(), cmap='coolwarm', annot=True, fmt='.2f', ax=axes[1])\naxes[1].set_title('Correlation Heatmap - Original Data')\n\n# Test Data Heatmap\nsns.heatmap(test_data.corr(), cmap='coolwarm', annot=True, fmt='.2f', ax=axes[2])\naxes[2].set_title('Correlation Heatmap - Test Data')\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T17:36:00.101032Z","iopub.execute_input":"2025-03-10T17:36:00.101296Z","iopub.status.idle":"2025-03-10T17:36:03.265738Z","shell.execute_reply.started":"2025-03-10T17:36:00.101272Z","shell.execute_reply":"2025-03-10T17:36:03.264297Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Correlation Analysis of Numerical Variables**\n\n**General Observations Across All Datasets:**  \n\n**Temperature Correlations:**\n- maxtemp, temperature, and mintemp exhibit very strong positive correlations across all datasets. This indicates that these temperature-related features move together consistently and possible redudency between these numerical features.\n- They show strong negative correlations with pressure.\n- They show a strong positive correlation with dewpoint.\n\n**Pressure Correlations:**\n- pressure has strong negative correlations with all temperature-related features and dewpoint across all datasets.\n- pressure has a moderate positive correlation with windspeed.\n\n**Humidity Correlations:**\n- humidity shows a moderate positive correlation with cloud and a moderate negative correlation with sunshine across all datasets.\n- humidity has a moderate positive correlation with rainfall.\n\n**Cloud and Sunshine Correlations:**\n- cloud and sunshine have a strong negative correlation, indicating that cloudy conditions are associated with less sunshine.\n- cloud has a moderate positive correlation with rainfall.\n\n**Wind Direction Correlations:**\n- winddirection has a moderate negative correlation with pressure and a moderate positive correlation with the temperature related columns.\n\n**Rainfall Correlations:**\n- rainfall has a moderate positive correlation with humidity and cloud and a moderate negative correlation with sunshine.\n\n**Intresting Thoughts**\n- The moderate correlation in winddirection and temperature could suggest that wind direction may be associated with warmer air masses?","metadata":{}},{"cell_type":"markdown","source":"## **KDE Plots for Target and Numerical Varible Relationship**","metadata":{}},{"cell_type":"code","source":"# KDE plot for Feature-Target Relationship\nplt.figure(figsize=(14, 10))\nfor i, col in enumerate(numerical_variables, 1):\n    plt.subplot(3, 4, i)\n    sns.kdeplot(train_data[col][train_data['rainfall'] == 1], color='red', label='Rainfall: 1')\n    sns.kdeplot(train_data[col][train_data['rainfall'] == 0], color='blue', label='Rainfall: 0')\n    plt.title(f'Distribution of {col} by Rainfall')\n    plt.legend()\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T17:36:03.266756Z","iopub.execute_input":"2025-03-10T17:36:03.267075Z","iopub.status.idle":"2025-03-10T17:36:19.634034Z","shell.execute_reply.started":"2025-03-10T17:36:03.267047Z","shell.execute_reply":"2025-03-10T17:36:19.632971Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Pair Plots for Numerical Variable Relationships**\n","metadata":{}},{"cell_type":"code","source":"#Visualising relationships between variables\nsns.pairplot(train_data[numerical_variables + ['rainfall']], hue='rainfall', palette='coolwarm', diag_kind='kde')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Transformations of Skewed Data**","metadata":{}},{"cell_type":"code","source":"log_transformation = ['sunshine', 'windspeed', 'cloud', 'humidity', 'dewpoint']\n\nfor col in log_transformation:\n    train_data[f'log_{col}'] = np.log1p(train_data[col])\nfor col in log_transformation:\n    original_data[f'log_{col}'] = np.log1p(original_data[col])\nfor col in log_transformation:\n    test_data[f'log_{col}'] = np.log1p(test_data[col])\n\nfig, axes = plt.subplots(len(log_transformation), 2, figsize=(12, len(log_transformation) * 4))\n\nfor i, feature in enumerate(log_transformation):\n    # Histogram\n    sns.histplot(train_data[feature], label='Train Data', bins=20, kde=True, ax=axes[i, 0])\n    sns.histplot(test_data[feature], label='Test Data', bins=20, kde=True, ax=axes[i, 0])\n    sns.histplot(original_data[feature], label='Original Data', bins=20, kde=True, ax=axes[i, 0])\n    axes[i, 0].set_title(f'Histogram of log_{feature}')\n    axes[i, 0].legend()\n    axes[i, 0].grid(linestyle='--', linewidth=0.7)\n\n    # Horizontal Boxplot\n    sns.boxplot(data=[train_data[feature], test_data[feature], original_data[feature]], \n                orient='h', ax=axes[i, 1])\n    axes[i, 1].set_title(f'Horizontal Boxplot of log_{feature}')\n    axes[i, 1].set_yticklabels(['Train Data', 'Test Data', 'Original Data'])\n    axes[i, 1].grid(axis='x', linestyle='--', linewidth=0.7)\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T17:36:19.643815Z","iopub.execute_input":"2025-03-10T17:36:19.644153Z","iopub.status.idle":"2025-03-10T17:36:23.481336Z","shell.execute_reply.started":"2025-03-10T17:36:19.644118Z","shell.execute_reply":"2025-03-10T17:36:23.480246Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Feature Engineering**","metadata":{}},{"cell_type":"code","source":"def feature_engineering_data(data):\n    # Feature Engineering\n    data[\"dew_humidity\"] = data[\"dewpoint\"] * data[\"humidity\"] # ***\n    data[\"cloud_windspeed\"] = data[\"cloud\"] * data[\"windspeed\"] # ***\n    data[\"cloud_to_humidity\"] = data[\"cloud\"] / data[\"humidity\"]\n    data[\"temp_to_sunshine\"] = data[\"sunshine\"] / data[\"temparature\"] # ***\n\n    \n    #data[\"temp_range\"] = data[\"maxtemp\"] - data[\"mintemp\"]\n    #data[\"temp_from_dewpoint\"] = data[\"temparature\"] - data[\"dewpoint\"] # **?\n    #data[\"wind_speeddirection\"] = data[\"windspeed\"] * data[\"winddirection\"]\n    #data['avg_temp'] = (data['maxtemp'] + data['mintemp']) / 2\n    #data['cloud_persistence'] = data['cloud'] * data['sunshine']  # If both are low, it means the cloud cover persists.\n    #data['pressure_temp_ratio'] = data['pressure'] / (data['temparature'] + 1)  # Avoid division by zero.\n    #data['dew_temp_diff'] = data['temparature'] - data['dewpoint']\n    #data['dew_humidity_ratio'] = data['dewpoint'] / (data['humidity'] + 1)\n    #data['cloud_humidity_plus'] = data['cloud'] + data[\"humidity\"] \n    #data['cloud_humidity_sunshine_plus'] = data['cloud'] + data[\"humidity\"] + data['sunshine']\n    #data['cloud_sunshine_*'] = data['cloud'] * data['sunshine']\n    data['wind_temp_interaction'] = data['windspeed'] * data['temparature']\n    #data['sunshine_wind_interaction'] = data['sunshine'] + data['windspeed'] # *\n    #data['cloud_humidity_ratio'] = data['cloud'] + (data['humidity'])  # Avoid division by zero\n    #data['pressure_temp_ratio'] = data['pressure'] / (data['temparature'] + 1)  # Avoid division by zero\n    #data['cloud_wind_ratio'] = data['cloud'] / (data['windspeed'] + 1)  # Avoid division by zero\n\n\n    #data['cloud_coverage_rate'] = data['cloud'] / 100  # Normalize to 0-1 range \n    #data['cloud_sun_interaction'] = data['cloud'] * (1 - data['sunshine'])\n\n    \n    #data['weather_severity'] = (data['cloud'] * data['humidity']) / (data['pressure'] * (data['sunshine'] + 1))\n    data['cloud_sun_ratio'] = data['cloud'] / (data['sunshine'] + 1) # ***\n    #data[\"cloud_sunshine_+\"] = data[\"cloud\"] + data[\"sunshine\"]\n    #data[\"cloud_sunshine_-\"] = data[\"cloud\"] - data[\"sunshine\"]\n    data[\"dew_humidity/sun\"] = data[\"dewpoint\"] * data[\"humidity\"] / (data['sunshine'] + 1)\n    data[\"dew_humidity_+\"] = data[\"dewpoint\"] * data[\"humidity\"]\n    \n\n    data['humidity_sunshine_*'] = data[\"humidity\"] * data['sunshine']\n\n    data[\"cloud_humidity/pressure\"] = (data[\"cloud\"] * data[\"humidity\"]) / data[\"pressure\"]\n    \n\n    # Extract temporal features\n    data['month'] = ((data['day'] - 1) // 30 + 1).clip(upper=12)\n    data['season'] = data['month'].apply(lambda x: 1 if 3 <= x <= 5  # Spring\n                                         else 2 if 6 <= x <= 8  # Summer\n                                         else 3 if 9 <= x <= 11  # Autumn\n                                         else 0)  # Winter\n    # Seasonal trends\n    #data['season_temp_trend'] = data['temparature'] * data['season']\n    data['season_cloud_trend'] = data['cloud'] * data['season']\n    \n\n    # Seasonal deviation from mean values\n    data['season_cloud_deviation'] = data['cloud'] - data.groupby('season')['cloud'].transform('mean')\n    data['season_temperature'] = data['temparature'] * data['season']  # Interaction of temper\n\n\n\n    \n    data = data.drop(columns=[\"month\"])\n    #data['season_temp_trend'] = data['avg_temp'] * data['season']\n    #data['season_dewpoint_trend'] = data['dewpoint'] * data['season']\n    #data[\"dew_humidity_with_season\"] = data['humidity'] * data['season']\n    \n    data = data.drop(columns=[\"maxtemp\", \"winddirection\",\"humidity\",\"temparature\",\"pressure\",\"day\",\"season\"])\n\n    return data\n\n# Apply to train and test datasets\ntrain_data = feature_engineering_data(train_data)\ntest_data = feature_engineering_data(test_data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T17:36:23.482441Z","iopub.execute_input":"2025-03-10T17:36:23.482727Z","iopub.status.idle":"2025-03-10T17:36:23.502089Z","shell.execute_reply.started":"2025-03-10T17:36:23.482702Z","shell.execute_reply":"2025-03-10T17:36:23.500999Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sns.heatmap(train_data.corr(), cmap='coolwarm', annot=True, fmt='.2f', ax=axes[0])\naxes[0].set_title('Correlation Heatmap - Train Data')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Model and Feature Analysis**","metadata":{}},{"cell_type":"code","source":"# Select features and target variable\nX = train_data.drop(['rainfall', 'id'], axis=1)\ny = train_data['rainfall']\nX_test = test_data.drop(['id'], axis=1)\n\n# Standardize the features\nscaler = StandardScaler()\nX = scaler.fit_transform(X)\nX_test = scaler.transform(X_test)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"models = {\n    \"Logistic Regression\": LogisticRegression(random_state=42,max_iter=1000),\n    \"Random Forest\": RandomForestClassifier(random_state=42, n_estimators=100),\n    \"Gradient Boosting\": GradientBoostingClassifier(random_state=42),\n    \"Support Vector Machine\": SVC(probability=True, random_state=42),\n    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n    \"Neural Network\": MLPClassifier(random_state=42, max_iter=100, hidden_layer_sizes=(10)),\n    \"XGBoost\": XGBClassifier(random_state=42, n_estimators=100, learning_rate=0.05, max_depth=6),\n    \"CatBoost\": CatBoostClassifier(random_state=42, iterations=100, learning_rate=0.14, depth=6, verbose=0)\n}\n\n# Train models using StratifiedKFold CV\nFOLDS = 13\nskf = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=42)\nauc_scores = {}\nroc_curves = {}\n\nfor name, model in models.items():\n    oof_preds = np.zeros(len(y))\n    \n    for train_idx, val_idx in skf.split(X, y):\n        X_train, X_val = X[train_idx], X[val_idx]\n        y_train, y_val = y[train_idx], y[val_idx]\n\n        \n        if hasattr(model, 'fit'):\n            if \"eval_set\" in model.fit.__code__.co_varnames:\n                model.fit(X_train, y_train, eval_set=[(X_val, y_val)], early_stopping_rounds=50, verbose=0)\n            else:\n                model.fit(X_train, y_train)\n        \n        oof_preds[val_idx] = model.predict_proba(X_val)[:, 1]\n    \n    auc_score = roc_auc_score(y, oof_preds)\n    auc_scores[name] = auc_score\n    fpr, tpr, _ = roc_curve(y, oof_preds)\n    roc_curves[name] = (fpr, tpr, auc_score)\n    print(f\"{name}: AUC = {auc_score:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **ROC Curve Comparison**","metadata":{}},{"cell_type":"code","source":"# Plot ROC curves\nplt.figure(figsize=(8, 6))\nfor model_name, (fpr, tpr, auc_score) in roc_curves.items():\n    plt.plot(fpr, tpr, label=f\"{model_name} (AUC = {auc_score:.4f})\")\nplt.plot([0, 1], [0, 1], 'k--')\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.title(\"ROC Curve Comparison\")\nplt.legend()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Submission File**","metadata":{}},{"cell_type":"code","source":"# Predictions for the test set with the top N features\ntest_preds = best_model.predict_proba(X_test_top)[:, 1]\n\n# Submission\nsubmission = pd.DataFrame({'id': test_data['id'], 'rainfall': test_preds})\nsubmission.to_csv(\"submission.csv\", index=False)\nprint(\"Submission file saved as 'submission.csv'.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}